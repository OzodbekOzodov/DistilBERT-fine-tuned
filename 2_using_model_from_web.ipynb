{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the fine-tuned DistilBERT Sentiment Analysis for Monetary Policy Speech Classification Model from Hugging Face\n",
    "## Introduction\n",
    "\n",
    "This guide provides step-by-step instructions on how to use a fine-tuned DistilBERT model for sentiment analysis. The model is hosted on Hugging Face and is specifically trained for monetary policy-related texts.\n",
    "\n",
    "## Prerequisites\n",
    "Ensure you have Python and pip installed in your environment.\n",
    "\n",
    "# Steps to Use the Model\n",
    "- Setting up the Environment\n",
    "\n",
    "It's good practice to clear any previous models or variables in your environment before loading a new model. This ensures there are no conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Model\n",
    "\n",
    "- Load the DistilBERT tokenizer, which is exactly the same tokenizer used to train the model, for converting your input text into a format that the model understands.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-10 13:41:45.746489: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342673a48f67431797e13d96becacb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a219f2dd3b4229a098ad84b434068f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "# Load the DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Load your fine-tuned model from the Hugging Face Model Hub\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"OOzodbek/distilbert-for-monetary-policy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fine-tuned model from Hugging Face using the specified repository name.\n",
    "Define the Sentiment Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def classify_sentiment(text):\n",
    "    \"\"\"\n",
    "    Classifies the sentiment of a given text as either 'Positive' or 'Negative' using a pre-trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The input text string to be classified.\n",
    "    \n",
    "    Returns:\n",
    "    - str: 'Positive' if the sentiment of the text is positive, otherwise 'Negative'.\n",
    "    \n",
    "    Note:\n",
    "    Assumes that a pre-trained model named 'model' and its associated tokenizer 'tokenizer' are already loaded.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Get model's prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        prediction = torch.argmax(probs, dim=1).item()  # 0 or 1\n",
    "\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broad example\n",
    "Take a look at how we can leverage the model using random example sentences. For now, due to the limitations in time, resources and scalability, we can get one of only two classes predicted. There is a room for huge improvement in terms of how classes are accurately defined, as well as number of classes that can say how strong or mild the sentiments are, but let's keep them for future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: The central bank announced a rate cut, aiming to stimulate the economy.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Inflation has been steadily increasing over the past few months.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: Analysts predict a robust economic recovery next year.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Concerns grow over the ballooning national debt.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: The recent fiscal policies have shown a positive impact on job growth.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Foreign investments have seen a significant decline this quarter.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Housing markets are expected to stabilize with the new subsidy.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Trade deficits remain a persistent challenge for the policymakers.\n",
      "Sentiment: Negative\n",
      "\n",
      "Text: The tech sector continues to drive economic growth.\n",
      "Sentiment: Positive\n",
      "\n",
      "Text: Consumer spending has surged, signaling economic optimism.\n",
      "Sentiment: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List of demonstration sentences\n",
    "sentences = [\n",
    "    \"The central bank announced a rate cut, aiming to stimulate the economy.\",\n",
    "    \"Inflation has been steadily increasing over the past few months.\",\n",
    "    \"Analysts predict a robust economic recovery next year.\",\n",
    "    \"Concerns grow over the ballooning national debt.\",\n",
    "    \"The recent fiscal policies have shown a positive impact on job growth.\",\n",
    "    \"Foreign investments have seen a significant decline this quarter.\",\n",
    "    \"Housing markets are expected to stabilize with the new subsidy.\",\n",
    "    \"Trade deficits remain a persistent challenge for the policymakers.\",\n",
    "    \"The tech sector continues to drive economic growth.\",\n",
    "    \"Consumer spending has surged, signaling economic optimism.\"\n",
    "]\n",
    "\n",
    "# Getting the model's sentiment predictions for each sentence\n",
    "for sentence in sentences:\n",
    "    sentiment = classify_sentiment(sentence)\n",
    "    print(f\"Text: {sentence}\\nSentiment: {sentiment}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# Use Cases\n",
    "Monetary Policy Analysis: Use this model to gauge sentiment from monetary policy statements or central bank minutes.\n",
    "Research & Academic: For those studying monetary policies, this can be a tool to quickly gauge the sentiment of large volumes of text.\n",
    "Potential Failures and Considerations\n",
    "Domain-Specific: This model is trained on monetary policy texts, so using it for general sentiment analysis or other domains might not yield accurate results.\n",
    "Input Length: Ensure your input texts are not excessively long. For best results, keep them under 512 tokens.\n",
    "First Trial Model: This model is an initial version. As with any machine learning model, it's important to remember that predictions are not always 100% accurate. Always use model predictions as a supplementary tool rather than the sole decision-making criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial-text-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
